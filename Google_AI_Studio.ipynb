{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t8101349/Colab-/blob/master/Google_AI_Studio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10054535-e70f-415d-8818-4577f2d6589e",
      "metadata": {
        "id": "10054535-e70f-415d-8818-4577f2d6589e"
      },
      "source": [
        "# Google AI Studio\n",
        "* https://aistudio.google.com/\n",
        "* https://ai.google.dev/gemini-api/docs?hl=zh-tw\n",
        "* https://ai.google.dev/gemini-api/docs/get-started/tutorial?lang=python&hl=zh-tw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3360bfe0-a397-405b-975a-31dac2fedbcd",
      "metadata": {
        "id": "3360bfe0-a397-405b-975a-31dac2fedbcd"
      },
      "outputs": [],
      "source": [
        "# ! pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "69f801ba-bbb6-4840-95ca-c83d44d4ef0e",
      "metadata": {
        "id": "69f801ba-bbb6-4840-95ca-c83d44d4ef0e"
      },
      "outputs": [],
      "source": [
        "API_KEY = \"AIzaSyB0J1JGktKYOfMhrJxT7IBhATh5xqTnW70\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZkzfEupWxG8",
        "outputId": "628d9506-e42e-4752-efc8-e79bbdc293f3"
      },
      "id": "4ZkzfEupWxG8",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.20.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.2 (from gradio)\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.20.1-py3-none-any.whl (62.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.20.1 gradio-client-1.7.2 groovy-0.1.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.10 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ac1017d-7c97-4f31-b9fc-597bf2dec57c",
      "metadata": {
        "id": "7ac1017d-7c97-4f31-b9fc-597bf2dec57c"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5cacc854-9774-4cae-a7da-b2ff871207a0",
      "metadata": {
        "id": "5cacc854-9774-4cae-a7da-b2ff871207a0"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "genai.configure(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fd31d43-a13d-4dfb-8625-906294edee0e",
      "metadata": {
        "id": "1fd31d43-a13d-4dfb-8625-906294edee0e"
      },
      "source": [
        "## 產生文字"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a19f9a87-09f0-4b3b-969d-5cb74a3d251c",
      "metadata": {
        "id": "a19f9a87-09f0-4b3b-969d-5cb74a3d251c",
        "outputId": "9af05a92-45c7-4664-a8f2-af4a36936405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "機器學習 (Machine Learning, ML) 是一種人工智慧 (AI) 的子領域，其定義可以從以下幾個關鍵方面來理解：\n",
            "\n",
            "**核心定義：**\n",
            "\n",
            "*   機器學習是一種**讓電腦系統能夠從數據中學習，而無需進行明確程式設計**的技術。 換句話說，機器學習演算法允許電腦在沒有被明確告知如何解決問題的情況下，通過經驗來改善自身的性能。\n",
            "*   Arthur Samuel (1959) 的經典定義是：**「機器學習是一種賦予電腦在沒有明確程式設計的情況下進行學習的能力的學科。」**\n",
            "\n",
            "**更詳細的解釋：**\n",
            "\n",
            "*   **從數據學習：** 機器學習演算法使用大量的數據作為訓練集。 這些數據被用來調整演算法的內部參數，使其能夠識別模式、做出預測或進行決策。\n",
            "*   **無需明確程式設計：**  與傳統的程式設計不同，機器學習工程師不會編寫具體的指令來告訴電腦如何完成任務。 相反，他們設計演算法，讓演算法自己從數據中找到完成任務的最佳方法。\n",
            "*   **性能改善：** 隨著演算法接觸到更多的數據，它會不斷地調整自身，從而提高其在特定任務上的性能（例如，更準確的預測、更有效的分類）。\n",
            "*   **自動化：** 機器學習的一個重要優勢是能夠自動化許多原本需要人工完成的任務，例如圖像識別、語言翻譯、風險評估等。\n",
            "\n",
            "**更進一步的理解：**\n",
            "\n",
            "機器學習演算法的學習過程可以被看作是**一個優化過程**。演算法會不斷地調整自身的參數，以最小化某個**損失函數 (Loss Function)**。 損失函數衡量演算法的預測結果與實際結果之間的差異。 通過最小化損失函數，演算法就能夠學習到從數據中產生準確預測的方法。\n",
            "\n",
            "**總結：**\n",
            "\n",
            "機器學習是一種強大的工具，它讓電腦能夠從數據中學習，並在沒有明確程式設計的情況下解決複雜的問題。 它的核心思想是通過經驗（數據）來改善性能，並自動化許多原本需要人工完成的任務。\n",
            "\n",
            "**常見的機器學習任務包括：**\n",
            "\n",
            "*   **分類 (Classification):** 將數據點分配到不同的類別中 (例如，垃圾郵件過濾)。\n",
            "*   **回歸 (Regression):** 預測一個連續數值 (例如，房價預測)。\n",
            "*   **聚類 (Clustering):** 將相似的數據點分組在一起 (例如，客戶分群)。\n",
            "*   **降維 (Dimensionality Reduction):** 減少數據的維度，同時保留重要的資訊 (例如，特徵提取)。\n",
            "*   **生成模型 (Generative Models):** 學習數據的分佈，並生成新的、類似於訓練數據的數據 (例如，圖像生成)。\n",
            "*   **強化學習 (Reinforcement Learning):** 訓練一個智能體在一個環境中採取行動，以最大化累積獎勵 (例如，遊戲 AI)。\n",
            "\n",
            "希望這個解釋對您有所幫助！\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"機器學習的定義\"\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abcb0c38-81d2-471c-a855-10f404c9a193",
      "metadata": {
        "id": "abcb0c38-81d2-471c-a855-10f404c9a193"
      },
      "source": [
        "### 產生文字串流"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1d34b9dd-2600-4338-b25f-3f58b0f6ed80",
      "metadata": {
        "id": "1d34b9dd-2600-4338-b25f-3f58b0f6ed80",
        "outputId": "2549a938-b78a-4c2f-b4ca-153ad9eb4d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "機器\n",
            "________________________________________________________________________________\n",
            "學習 (Machine\n",
            "________________________________________________________________________________\n",
            " Learning, ML) 是一個**讓電腦從資料中學習，而不需要明確\n",
            "________________________________________________________________________________\n",
            "地程式設計**的領域。 更精確地說，它是**在\n",
            "________________________________________________________________________________\n",
            "不經過顯式編程的情況下，使計算機能夠學習的算法和統計模型的科學研究。**\n",
            "\n",
            "以下是幾個更詳細的定義，\n",
            "________________________________________________________________________________\n",
            "它們強調了不同的面向：\n",
            "\n",
            "* **經驗改進:** 機器學習是通過經驗自動改進電腦系統性能的過程。  換句話說，系統\n",
            "________________________________________________________________________________\n",
            "通過處理更多數據，其完成特定任務的能力會提高。\n",
            "* **模式識別和預測:** 機器學習著重於發展可以存取數據並自行學習的電腦程式。 學習的目標通常是預測或識別數據\n",
            "________________________________________________________________________________\n",
            "中的模式。\n",
            "* **演算法設計:**  機器學習致力於設計和開發能夠從數據中學習的演算法。 這些演算法利用統計技術來識別模式、做出預測或進行決策。\n",
            "* **問題\n",
            "________________________________________________________________________________\n",
            "解決方法:**  機器學習提供了一種解決問題的新方法，特別是那些涉及大量數據，複雜關係或不斷變化的環境的問題。\n",
            "\n",
            "**核心概念:**\n",
            "\n",
            "* **資料 (Data):** 機器學習的燃料。 演算法從資料中學習模式和關係。\n",
            "* **演\n",
            "________________________________________________________________________________\n",
            "算法 (Algorithm):**  用於學習資料的特定數學或計算過程。\n",
            "* **模型 (Model):**  從資料中學習到的知識的表示形式。 模型可以被用於預測新資料或做出決策。\n",
            "* **訓練 (Training):**  使用資料調整演算法參數以創建\n",
            "________________________________________________________________________________\n",
            "模型的過程。\n",
            "* **預測 (Prediction):**  使用訓練好的模型對新資料進行預測或分類。\n",
            "\n",
            "**總結來說，機器學習就是讓電腦有能力去學習、適應和做出預測，而不需要人類明確地告訴它們該怎麼做。 它是一種利用資料\n",
            "________________________________________________________________________________\n",
            "和演算法來賦予電腦智慧的強大技術。**\n",
            "\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "prompt = \"機器學習的定義\"\n",
        "\n",
        "response = model.generate_content(prompt, stream=True)\n",
        "\n",
        "for chunk in response:\n",
        "  print(chunk.text)\n",
        "  print(\"_\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e036c6b7-0a6b-4efc-91a9-7965087e482d",
      "metadata": {
        "id": "e036c6b7-0a6b-4efc-91a9-7965087e482d"
      },
      "source": [
        "## 多模態"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6e2756a1-6a7e-450d-962a-72df35515681",
      "metadata": {
        "id": "6e2756a1-6a7e-450d-962a-72df35515681",
        "outputId": "552c6709-d1f5-4744-d295-64788936cbe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "[\n",
            "    {\"class\":\"人臉\", \"corr\":[53,161,175,233], \"id\":1, \"age\":55, \"gender\":\"男性\"},\n",
            "    {\"class\":\"人臉\", \"corr\":[266,166,140,188], \"id\":2, \"age\":25, \"gender\":\"女性\"},\n",
            "    {\"class\":\"人臉\", \"corr\":[435,170,141,186], \"id\":3, \"age\":26, \"gender\":\"男性\"},\n",
            "    {\"class\":\"人臉\", \"corr\":[638,179,121,170], \"id\":4, \"age\":50, \"gender\":\"女性\"}\n",
            "]\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import google.generativeai as genai\n",
        "import urllib.request\n",
        "\n",
        "# image1 = {\n",
        "#     'mime_type': 'image/jpeg',\n",
        "#     'data': pathlib.Path('image1.jpg').read_bytes()\n",
        "# }\n",
        "\n",
        "# image1 = {\n",
        "#     'mime_type': 'image/jpeg',\n",
        "#     'data': urllib.request.urlopen(\"https://img.ltn.com.tw/Upload/health/page/800/2022/01/01/phprhI3u1.jpg\").read()\n",
        "# }\n",
        "# prompt = \"照片中有幾根香蕉\"\n",
        "\n",
        "image1 = {\n",
        "    'mime_type': 'image/jpeg',\n",
        "    'data': urllib.request.urlopen(\"https://mentorx.tw/wp-content/gallery/corn_20170511/a_KLB_0298.jpg\").read()\n",
        "}\n",
        "prompt = '''\n",
        "列出照片中人臉的座標，請嚴格按照下面的JSON格式來輸出結果\n",
        "<JSON>\n",
        "[\n",
        "    {\"class\":\"人臉\", \"corr\":[X,Y,W,H], \"id\":1, \"age\":年齡, \"gender\":性別},\n",
        "    {\"class\":\"人臉\", \"corr\":[X,Y,W,H], \"id\":2, \"age\":年齡, \"gender\":性別},\n",
        "    {\"class\":\"人臉\", \"corr\":[X,Y,W,H], \"id\":3, \"age\":年齡, \"gender\":性別},\n",
        "]\n",
        "</JSON>\n",
        "'''\n",
        "\n",
        "# image1 = {\n",
        "#     'mime_type': 'image/jpeg',\n",
        "#     'data': urllib.request.urlopen(\"https://img.ltn.com.tw/Upload/health/page/800/2022/01/01/phprhI3u1.jpg\").read()\n",
        "# }\n",
        "# prompt = '''\n",
        "# 列出照片中物件的座標，請嚴格按照下面的JSON格式來輸出結果。\n",
        "# 辨識的物件限定為{香蕉、西瓜、蘋果}\n",
        "# <JSON>\n",
        "# [\n",
        "#     {\"class\":\"物件名稱\", \"corr\":[X,Y,W,H], \"id\":1, \"color\":\"物件顏色\"},\n",
        "#     {\"class\":\"物件名稱\", \"corr\":[X,Y,W,H], \"id\":2, \"color\":\"物件顏色\"},\n",
        "#     {\"class\":\"物件名稱\", \"corr\":[X,Y,W,H], \"id\":3, \"color\":\"物件顏色\"},\n",
        "# ]\n",
        "# </JSON>\n",
        "# '''\n",
        "\n",
        "\n",
        "response = model.generate_content([prompt, image1])\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ae5c8b9c-8b34-402a-90af-1e5bd30d281b",
      "metadata": {
        "id": "ae5c8b9c-8b34-402a-90af-1e5bd30d281b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "08b0a017-a483-4910-bbea-49a446e3ee9b",
      "metadata": {
        "id": "08b0a017-a483-4910-bbea-49a446e3ee9b",
        "outputId": "f0c0736a-c308-4b96-886f-a513e344888e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*   [人工智慧]\n",
            "*   [Data Science]\n",
            "*   [程式語言]\n",
            "*   [微軟技術]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "book = '''\n",
        "內容介紹:\n",
        "\n",
        "▍attention / self-attention 機制、Transformer、GPT...，大型語言模型 (LLM) 背後的先進技術「硬派」揭密！\n",
        "\n",
        "▍AI 界扛霸子 NVIDIA 的深度學習 (Deep Learning) 指定教材！\n",
        "\n",
        "近年來，在 NVIDIA (輝達) GPU、CUDA 技術的推波助瀾下，深度學習 (Deep Learning) 領域有著爆炸性的成長，例如最為人知的 ChatGPT 正是運用深度學習技術開發出來的當紅應用。\n",
        "\n",
        "□【徹底看懂 ChatGPT 背後核心技術 - Transformer、GPT 的模型架構】\n",
        "\n",
        "自從 ChatGPT 爆紅之後，自然語言處理 (NLP) 一直是深度學習的熱門研究話題，ChatGPT 的背後核心是 GPT 模型，而 GPT 裡面最重要最重要的技術就是最後那個「T」- 也就是大名鼎鼎、使用了 attention (注意力) 機制的 Transformer 模型，這當中所用的建模技術可說是一環扣一環，也容易讓初學者學起來暈的不得了，只要一個關鍵地方沒搞懂，後面就全花了...\n",
        "\n",
        "為此，本書經過精心設計，是帶你看懂 Transformer、GPT...這些先進技術的最佳救星！本書設計了「環環相扣」的 NLP 章節內容，從最末章的 GPT 模型往回推，循序漸進介紹各技術的細節：\n",
        "\n",
        "🔹看懂循環神經網路的缺點就知道為什麼需要 attention 機制以及 seq2seq 架構\n",
        "🔹看懂 attention 機制就能看懂 self-attention 機制\n",
        "🔹看懂 seq2seq 架構就能看懂 Transformer 的 encoder-decoder 架構\n",
        "🔹看懂 self-attention、seq2seq 就能看懂 Transformer\n",
        "🔹看懂 Transformer 就能看懂 GPT\n",
        "\n",
        "你可以深刻感受到次一章的模型架構幾乎都是為了解決前一章模型的特定問題而誕生的，經此一輪學習下來，保證讓你對 attention / self-attention 機制、Transformer、GPT 技術清清楚楚！這絕對是其他書看不到的精彩內容！\n",
        "\n",
        "【★學深度學習先進技術，跟 AI 重要推手 - NVIDIA 學最到位！】\n",
        "\n",
        "NVIDIA 除了在硬體上為 AI 帶來助益外，為了幫助眾多初學者快速上手深度學習，任職於 NVIDIA 的本書作者 Magnus Ekman 凝聚了他多年來在 NVIDIA 所積累的 AI 知識撰寫了本書。本書同時也是 NVIDIA 的教育和培訓部門 -【深度學習機構 (Deep Learning Institute, DLI)】 指定的培訓教材 (https://www.nvidia.com/zh-tw/training/books/)。\n",
        "\n",
        "要學深度學習，跟深度學習的重要推手 NVIDIA 學就對了！眾多紮實的內容保證讓你受益滿滿！\n",
        "\n",
        "本書特色:\n",
        "\n",
        "□【看懂 ChatGPT 背後核心技術 - GPT 的模型架構】\n",
        "attention 機制、self-attention 機制、Transformer、GPT、encoder-decoder、seq2seq、query-key-value 機制、Multi-head、位置編碼 (positional encoding)、預訓練 (pre-train)、微調 (fine-tune)...各種建模技術輕鬆搞懂！\n",
        "\n",
        "□【生成式 AI 語言模型 100% 從零開始打造！】\n",
        "‧用 Colab + tf.Keras 實作【多國語言翻譯模型】、【Auto-Complete 文字自動完成模型】\n",
        "‧從處理原始文字訓練資料 → 切割資料集 → 建構模型 → 模型調校、優化，從頭到尾示範一遍，帶你紮穩大型語言模型 (LLM) 的建模基礎\n",
        "\n",
        "□【深度學習基礎知識學好學滿】\n",
        "‧紮穩根基！不被損失函數 / 梯度下降 / 反向傳播 / 正規化 / 常規化…一拖拉庫技術名詞搞的暈頭轉向！\n",
        "‧深度神經網路基礎 / CNN / RNN / LSTM...基礎概念詳解\n",
        "‧多模態學習 (multimodal learning)、多任務學習 (multitask learning)、自動化模型架構搜尋...熱門主題介紹。\n",
        "\n",
        "□詳細解說, 流暢翻譯\n",
        "本書由【施威銘研究室】監修, 書中針對原書進行大量補充, 並適當添加註解, 幫助讀者更加理解內容！\n",
        "\n",
        "作者簡介\n",
        "Magnus Ekman\n",
        "\n",
        "現為 NVIDIA 架構總監，擁有資訊工程博士學位與多項專利。他於 1990 年代後期首次接觸人工神經網路、親身體會進化計算的威力後，開始鑽研計算機架構，並與妻兒遷往矽谷居住。他曾在昇陽電腦和 Samsung Research America 從事處理器設計和研發。他目前在 NVIDIA 領導一個工程團隊，負責開發自駕車、人工智慧 (AI) 資料中心專用的高效能、低功率 CPU。\n",
        "\n",
        "目錄大綱\n",
        "Ch01 從感知器看神經網路的底層知識\n",
        "1-1  最早的人工神經元 - Rosenblatt 感知器\n",
        "1-2  增加感知器模型的能力\n",
        "1-3  用線性代數實現神經網路模型\n",
        "\n",
        "Ch02 梯度下降法與反向傳播\n",
        "2-1  導數的基礎概念\n",
        "2-2  以梯度下降法 (gradient descent) 對模型訓練問題求解\n",
        "2-3  反向傳播 (back propagation)\n",
        "\n",
        "Ch03 多層神經網路的建立與調校\n",
        "3-1  動手實作：建立辨識手寫數字的多層神經網路\n",
        "3-2  改善神經網路的訓練成效\n",
        "3-3  實驗：調整神經網路與學習參數\n",
        "\n",
        "Ch04 用卷積神經網路 (CNN) 進行圖片辨識\n",
        "4-1  卷積神經網路 (CNN)\n",
        "4-2  實作：以卷積神經網路做圖片分類\n",
        "4-3  更深層的 CNN 與預訓練模型\n",
        "\n",
        "Ch05 用循環神經網路 (RNN、LSTM...) 處理序列資料\n",
        "5-1  RNN 的基本概念\n",
        "5-2  RNN 範例：預測書店銷售額\n",
        "5-3  LSTM (長短期記憶神經網路)\n",
        "5-4  LSTM 範例：文字的 Auto-Complete 機制\n",
        "\n",
        "Ch06 自然語言處理的重要前置工作：建立詞向量空間\n",
        "6-1  詞向量空間的基本知識\n",
        "6-2  做法(一)：在神經網路建模過程中「順便」生成詞向量空間\n",
        "6-3  做法(二)：以 word2vec、GloVe 專用演算法生成詞向量空間\n",
        "\n",
        "Ch07 用機器翻譯模型熟悉 seq2seq 架構\n",
        "7-1  機器翻譯模型的基本知識\n",
        "7-2  機器翻譯的範例實作\n",
        "7-2-1  tf.Keras 函數式 API 簡介\n",
        "7-2-2  建構模型前的工作\n",
        "7-2-3  建構模型\n",
        "7-2-4  訓練及測試模型\n",
        "7-2-5  實驗結果\n",
        "\n",
        "Ch08 認識 attention 與 self-attention 機制\n",
        "8-1  熟悉 attention 機制\n",
        "8-2  認識 self-attention 機制\n",
        "8-2-1 self-attention 的基本概念\n",
        "8-2-2 self-attention 機制的算法\n",
        "8-2-3 multi-head (多頭) 的 self-attention 機制\n",
        "\n",
        "Ch09 Transformer、GPT 及其他衍生模型架構\n",
        "9-1  Transformer 架構\n",
        "9-1-1 編碼器端的架構\n",
        "9-1-2 解碼器端的架構\n",
        "9-1-3 Transformer 內的其他設計\n",
        "9-1-4 小編補充：觀摩 keras 官網上的 Transformer 範例\n",
        "9-2 Transformer 架構的衍生模型：GPT、BERT\n",
        "9-2-1  認識 GPT 模型\n",
        "9-2-2  認識 BERT 模型\n",
        "9-2-3 其他從 Transformer 衍生出的模型\n",
        "\n",
        "附錄 A 延伸學習 (一)：多模態、多任務...等模型建構相關主題\n",
        "附錄 B 延伸學習 (二)：自動化模型架構搜尋\n",
        "附錄 C 延伸學習 (三)：後續學習方向建議\n",
        "附錄 D 使用 Google 的 Colab 雲端開發環境\n",
        "'''\n",
        "\n",
        "prompt = '''\n",
        "請依照下面的書籍描述來將書籍進行分類，分類的類別只能從下面複選：\n",
        "[程式語言, Data Science, 人工智慧, 分散式架構, 系統開發, 行動軟體開發, 資料庫, 資訊科學, 軟體架構, 軟體測試, 軟體工程, 資訊安全, 網站開發, 前端開發, 架站軟體, 網頁設計, Adobe 軟體應用, Office 系列, 遊戲開發設計, UI/UX, 雲端運算, 區塊鏈與金融科技, 物聯網 IoT, 商業管理類, 電子電路電機類, 嵌入式系統, 視覺影音設計, 考試認證, 數學, 微軟技術, MAC OS 蘋果電腦, 其他, 兒童專區, 製圖軟體應用, 語言學習, 國家考試, 職涯發展, Java, 理工類, 網路通訊, 量子電腦]\n",
        "\n",
        "<書籍描述>\n",
        "{書籍描述}\n",
        "</書籍描述>\n",
        "'''\n",
        "\n",
        "\n",
        "response = model.generate_content(prompt.format(書籍描述=book))\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "539fe107-08d7-48b8-83af-ae34384791df",
      "metadata": {
        "id": "539fe107-08d7-48b8-83af-ae34384791df",
        "outputId": "23748d49-7a34-4de3-cb11-335e34d90652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5e1fe727e59890341e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5e1fe727e59890341e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'```json\\n[\\n\"程式語言\",\\n\"Java\",\\n\"軟體工程\",\\n\"資訊科學\"\\n]\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "genai.configure(api_key=API_KEY)\n",
        "prompt = '''\n",
        "請依照下面的書籍描述來將書籍進行分類，分類的類別只能從下面複選：\n",
        "[程式語言, Data Science, 人工智慧, 分散式架構, 系統開發, 行動軟體開發, 資料庫, 資訊科學, 軟體架構, 軟體測試, 軟體工程, 資訊安全, 網站開發, 前端開發, 架站軟體, 網頁設計, Adobe 軟體應用, Office 系列, 遊戲開發設計, UI/UX, 雲端運算, 區塊鏈與金融科技, 物聯網 IoT, 商業管理類, 電子電路電機類, 嵌入式系統, 視覺影音設計, 考試認證, 數學, 微軟技術, MAC OS 蘋果電腦, 其他, 兒童專區, 製圖軟體應用, 語言學習, 國家考試, 職涯發展, Java, 理工類, 網路通訊, 量子電腦]\n",
        "\n",
        "<書籍描述>\n",
        "{書籍描述}\n",
        "</書籍描述>\n",
        "\n",
        "輸出請嚴格按照下面的JSON格式\n",
        "<JSON>\n",
        "[類別1, 類別2, 類別3, ]\n",
        "</JSON>\n",
        "'''\n",
        "\n",
        "\n",
        "def book_label(book):\n",
        "    prompt2 = prompt.format(書籍描述=book)\n",
        "    response = model.generate_content(prompt2)\n",
        "    return response.text\n",
        "\n",
        "demo = gr.Interface(fn=book_label, inputs=[gr.Textbox(label=\"書籍描述\", lines=10)],\n",
        "    outputs=gr.Textbox(label=\"分類結果\"))\n",
        "demo.launch()\n",
        "book_label('dummy for java')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "75ce2d13-6e2b-44d9-988a-1ae07edd1ec9",
      "metadata": {
        "id": "75ce2d13-6e2b-44d9-988a-1ae07edd1ec9",
        "outputId": "42ec9888-8a6c-4d54-a715-f8e3e0a53480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"是否合適\": \"NO\",\n",
            "  \"適任度\": 10,\n",
            "  \"分析\": \"該求職者的學經歷背景明顯與工作需求不符。求職者擁有電子工程、資訊科學的博士學位，並在相關領域有豐富的研發及顧問經驗，專長在機器學習、影像識別、AI等高科技領域。然而，工作需求為財務會計助理，主要負責工程請款、帳務處理、銀行匯款等行政事務，以及審閱維修合約。雖然工作要求高中、專科、大學學歷，且科系要求財稅金融或會計相關，求職者學歷遠高於要求，但其專業背景與會計/財務領域並無關聯。即使求職者能勝任簡單的文書處理（Excel, Word, PowerPoint），但缺乏會計經驗（雖然要求一年以上），且不具備財稅金融相關學歷背景，也缺乏會計軟體經驗，例如不熟悉奇德系統，故判定不適合此職位。其能力明顯Overqualified，且技能點與職位需求幾乎沒有交集。即使能夠學習，但以其背景來說，不太可能穩定就任此工作。\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "工作需求='''\n",
        "工作內容\n",
        "1. 規劃及執行人工智慧系列課程設計。\n",
        "2. 課程教授與學員學習期間關懷。\n",
        "3. 備課與人工智慧相關新技術之導入。\n",
        "4. 課程教學\n",
        "\n",
        "職務類別\n",
        "講師、資料科學家、演算法工程師\n",
        "工作待遇\n",
        "待遇面議（經常性薪資達 4 萬元或以上）取得專屬你的薪水報告\n",
        "工作性質\n",
        "全職\n",
        "上班地點\n",
        "台北市大安區復興南路1段390號2樓 (距捷運大安站約130公尺)\n",
        "管理責任\n",
        "不需負擔管理責任\n",
        "出差外派\n",
        "無需出差外派\n",
        "上班時段\n",
        "日班\n",
        "休假制度\n",
        "依公司規定\n",
        "可上班日\n",
        "不限\n",
        "需求人數\n",
        "1人\n",
        "條件要求\n",
        "工作經歷\n",
        "2年以上\n",
        "學歷要求\n",
        "專科以上\n",
        "科系要求\n",
        "不拘\n",
        "語文條件\n",
        "不拘\n",
        "\n",
        "擅長工具\n",
        "Python、scikit-learn、OpenCV、Computer Vision、LLM、Prompt\n",
        "提升專業能力\n",
        "工作技能\n",
        "軟體程式設計、Machine Learning、深度學習、人工智慧、語言模型、演算法設計、提示工程、生成式AI\n",
        "其他條件\n",
        "未填寫\n",
        "'''\n",
        "\n",
        "個人履歷='''\n",
        "經歷：\n",
        "中原大學電子所博士\n",
        "\n",
        "中央研究院資訊科學所博士後研究員\n",
        "\n",
        "吉鴻電子資深工程師\n",
        "\n",
        "冠捷科技正工程師\n",
        "\n",
        "104人力銀行人資學院資料科學家\n",
        "\n",
        "長庚大學工商管理系兼任實務教師\n",
        "\n",
        "104人力銀行人資學院顧問\n",
        "\n",
        "\n",
        "現職：\n",
        "台灣人工智能產業協會講師\n",
        "\n",
        "實踐大學推廣中心講師\n",
        "\n",
        "緯育講師\n",
        "\n",
        "\n",
        "專案經驗：\n",
        "收鈔機韌體(偽鈔偵測)\n",
        "\n",
        "電視韌體\n",
        "\n",
        "交通執法系統\n",
        "\n",
        "高承載管制違規偵測系統\n",
        "\n",
        "手持式雷射測距儀\n",
        "\n",
        "區間測速系統\n",
        "\n",
        "違停偵測系統\n",
        "\n",
        "活動地磅系統\n",
        "\n",
        "測速照相系統\n",
        "\n",
        "人才適任與久任度評估系統\n",
        "\n",
        "\n",
        "專長：\n",
        "機器學習、影像識別、大語言模型、生成式AI、數位電路與嵌入式系統、程式設計\n",
        "'''\n",
        "\n",
        "工作需求2='''\n",
        "工作內容\n",
        "1.工程請款\n",
        "2.維修保養合約審閱\n",
        "3.開立發票\n",
        "4.處理廠商貨款或費用等應付款項帳務。\n",
        "5.銀行臨櫃匯款等作業。\n",
        "6.需具有1年以上會計經驗。\n",
        "7.主管交辦事項\n",
        "\n",
        "職務類別\n",
        "財務會計助理、記帳／出納／一般會計、財務分析／財務人員\n",
        "工作待遇\n",
        "月薪30,000~35,000元（固定或變動薪資因個人資歷或績效而異）取得專屬你的薪水報告\n",
        "工作性質\n",
        "全職\n",
        "上班地點\n",
        "台北市南港區南港路二段99-3號 (距捷運昆陽站約500公尺)\n",
        "管理責任\n",
        "不需負擔管理責任\n",
        "出差外派\n",
        "無需出差外派\n",
        "上班時段\n",
        "日班，08:30~18:00\n",
        "休假制度\n",
        "週休二日\n",
        "可上班日\n",
        "一個月內\n",
        "需求人數\n",
        "1人\n",
        "條件要求\n",
        "工作經歷\n",
        "1年以上\n",
        "學歷要求\n",
        "高中、專科、大學\n",
        "科系要求\n",
        "財稅金融相關、一般商業學類、會計學相關\n",
        "語文條件\n",
        "英文 -- 聽 /略懂、說 /略懂、讀 /略懂、寫 /略懂\n",
        "\n",
        "提升英文能力\n",
        "擅長工具\n",
        "Windows XP、Excel、PowerPoint、Word、天心資訊\n",
        "提升專業能力\n",
        "工作技能\n",
        "不拘\n",
        "其他條件\n",
        "1.熟悉會計軟體奇德系統尤佳\n",
        "2.工作細心，重視作業細節、具良好溝通、協調能力\n",
        "3.抗壓力高，面對問題或任務時，能獨立思考\n",
        "4.具流程優化能力及經驗佳\n",
        "'''\n",
        "\n",
        "\n",
        "prompt = '''\n",
        "你是一個人資面試官，請依據下面的個人履歷跟工作需求來分析求職者是否適合這份工作：\n",
        "\n",
        "<個人履歷>\n",
        "{個人履歷}\n",
        "</個人履歷>\n",
        "\n",
        "<工作需求>\n",
        "{工作需求}\n",
        "</工作需求>\n",
        "\n",
        "請嚴格按照下面的JSON格式來進行輸出：\n",
        "<JSON>\n",
        "{{'是否合適':'YES'或是'NO','適任度':0~100的評分,'分析':'詳細的理由'}}\n",
        "</JSON>\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "response = model.generate_content(prompt.format(個人履歷=個人履歷, 工作需求=工作需求2))\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e1b0faab-d22f-4ac8-9623-65e74054d240",
      "metadata": {
        "id": "e1b0faab-d22f-4ac8-9623-65e74054d240"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}